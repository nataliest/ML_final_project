{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# import tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test by recording sound [y/n]: n\n"
     ]
    }
   ],
   "source": [
    "# import pyaudio # source ~./bash... unset PYTHONPATH\n",
    "# import wave\n",
    "#\n",
    "# import librosa\n",
    "# import librosa.display\n",
    "# import librosa.feature\n",
    "\n",
    "# do_rec = input(\"Test by recording sound [y/n]: \")\n",
    "\n",
    "# FORMAT = pyaudio.paInt16\n",
    "# CHANNELS = 1\n",
    "# RATE = 8000\n",
    "# CHUNK = 1024\n",
    "# RECORD_SECONDS = 5\n",
    "# WAVE_OUTPUT_FILENAME = \"test_audio.wav\"\n",
    "# IMG_EXT = \".png\"\n",
    "\n",
    "# if do_rec.lower() == 'y':\n",
    "#     audio = pyaudio.PyAudio()\n",
    "\n",
    "#     # start Recording\n",
    "#     stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "#                     rate=RATE, input=True,\n",
    "#                     frames_per_buffer=CHUNK)\n",
    "#     print (\"recording...\")\n",
    "#     frames = []\n",
    "\n",
    "#     for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "#         data = stream.read(CHUNK)\n",
    "#         frames.append(data)\n",
    "#     print (\"finished recording\")\n",
    "\n",
    "\n",
    "#     # stop Recording\n",
    "#     stream.stop_stream()\n",
    "#     stream.close()\n",
    "#     audio.terminate()\n",
    "\n",
    "#     waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "#     waveFile.setnchannels(CHANNELS)\n",
    "#     waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "#     waveFile.setframerate(RATE)\n",
    "#     waveFile.writeframes(b''.join(frames))\n",
    "#     waveFile.close()\n",
    "    \n",
    "# #     plt.figure(figsize=(12, 12))\n",
    "#     y, sr = librosa.load(WAVE_OUTPUT_FILENAME)\n",
    "#     S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=256, fmax=4000)\n",
    "#     librosa.display.specshow(librosa.logamplitude(S,ref_power=np.max),\n",
    "#                             fmax=4000)\n",
    "#     output_filename = WAVE_OUTPUT_FILENAME[:-4] + \"_spec\" + IMG_EXT\n",
    "#     plt.savefig(output_filename, bbox_inches='tight', pad_inches = 0)\n",
    "#     librosa.display.specshow(librosa.logamplitude(S,ref_power=np.max),\n",
    "#                              y_axis='mel', fmax=4000, x_axis='time')\n",
    "#     plt.colorbar(format='%+2.0f dB')\n",
    "#     plt.title('Mel spectrogram')\n",
    "#     plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Convert audio files to spectrograms:\\n\\n\\n\\ndirectory = \"../test_audio/\"\\n\\nplt.figure(figsize=(12, 12))\\nfor filename in os.listdir(directory):\\n\\n    if filename[:1] != \\'.\\':\\n        path = os.path.join(directory, filename)\\n\\n        y, sr = librosa.load(path)\\n        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=256, fmax=4000)\\n        librosa.display.specshow(librosa.logamplitude(S,ref_power=np.max),\\n                                fmax=4000)\\n        output_filename = \"../test_spectrograms/\" + filename[:-4] + \"_spec\" + IMG_EXT\\n        plt.savefig(output_filename, bbox_inches=\\'tight\\', pad_inches = 0)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Convert audio files to spectrograms:\n",
    "\n",
    "\n",
    "\n",
    "directory = \"../test_audio/\"\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for filename in os.listdir(directory):\n",
    "\n",
    "    if filename[:1] != '.':\n",
    "        path = os.path.join(directory, filename)\n",
    "\n",
    "        y, sr = librosa.load(path)\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=256, fmax=4000)\n",
    "        librosa.display.specshow(librosa.logamplitude(S,ref_power=np.max),\n",
    "                                fmax=4000)\n",
    "        output_filename = \"../test_spectrograms/\" + filename[:-4] + \"_spec\" + IMG_EXT\n",
    "        plt.savefig(output_filename, bbox_inches='tight', pad_inches = 0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "\n",
    "import PIL\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Returns numpy image at size imageSize*imageSize\n",
    "def getProcessedData(img,imageSize, grayscale):\n",
    "    numchannels = 4\n",
    "    if grayscale:\n",
    "        numchannels = 2\n",
    "\n",
    "        \n",
    "                \n",
    "    img = img.resize((imageSize,imageSize), resample=Image.ANTIALIAS)\n",
    "#     print(np.shape(img))\n",
    "#     print(128*128*4)\n",
    "# #     imgData = np.asarray(img, dtype=np.uint8).reshape(imageSize,imageSize,1)\n",
    "#     imgData = np.asarray(img, dtype=np.uint8)\n",
    "#     print(np.shape(imgData))\n",
    "    imgData = np.array(img, dtype=np.uint8).reshape(img.size[0], img.size[1], numchannels)\n",
    "#     print(imgData)\n",
    "\n",
    "    imgData = imgData[:, :, :-1]\n",
    "    imgData = imgData/255.\n",
    "#     print(np.shape(imgData))\n",
    "#     print(imgData)\n",
    "#     img.save('greyscale.png')\n",
    "    return imgData\n",
    "\n",
    "#Returns numpy image at size imageSize*imageSize\n",
    "def getImageData(filename,imageSize, grayscale):\n",
    "    if grayscale:\n",
    "        img = Image.open(filename).convert('LA')\n",
    "    else:\n",
    "        img = Image.open(filename)\n",
    "\n",
    "#     height, width, channels = scipy.ndimage.imread(filename).shape\n",
    "#     print(\"&&\")\n",
    "#     print(height, width, channels)\n",
    "#     print(\"&&\")\n",
    "    imgData = getProcessedData(img, imageSize, grayscale)\n",
    "    return imgData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from random import shuffle\n",
    "# import pickle\n",
    "\n",
    "# directory = \"../test_spectrograms/\"\n",
    "\n",
    "# def createDataset(size, validationRatio, testRatio, grayscale):\n",
    "#     data = []\n",
    "#     numchannels = 3\n",
    "#     if grayscale:\n",
    "#         numchannels = 1\n",
    "#     count = 1\n",
    "#     #Add data (X,y)\n",
    "#     for filename in os.listdir(directory):\n",
    "#         if filename[:1] != '.':\n",
    "# #             if count > 10:\n",
    "# #                 break\n",
    "#             path = os.path.join(directory, filename)\n",
    "#             imgData = getImageData(path, size, grayscale)\n",
    "#             label = 1\n",
    "#             if filename[:4] == \"nois\" or filename[:4] == \"audi\":\n",
    "#                 label = 0\n",
    "#             data.append((imgData,label))\n",
    "# #             count += 1\n",
    "#     print(\"data size\", np.shape(data))\n",
    "# #     print(data)\n",
    "#     #Shuffle data\n",
    "#     shuffle(data)\n",
    "# #     print(data)\n",
    "#     print(\"data size\", np.shape(data))\n",
    "#     #Extract X and y\n",
    "#     X,y = zip(*data)\n",
    "#     print(\"X size\", np.shape(X))\n",
    "#     print(\"y size\", np.shape(y))\n",
    "#     #Split data\n",
    "#     validationNb = int(len(X)*validationRatio)\n",
    "#     testNb = int(len(X)*testRatio)\n",
    "#     trainNb = len(X)-(validationNb + testNb)\n",
    "#     print(validationNb, testNb, trainNb)\n",
    "\n",
    "#     #Prepare for Tflearn at the same time\n",
    "#     train_X = np.array(X[:trainNb]).reshape([-1, size, size, 1])\n",
    "#     train_y = np.array(y[:trainNb])\n",
    "#     validation_X = np.array(X[trainNb:trainNb+validationNb]).reshape([-1, size, size, 1])\n",
    "#     validation_y = np.array(y[trainNb:trainNb+validationNb])\n",
    "#     test_X = np.array(X[-testNb:]).reshape([-1, size, size, 1])\n",
    "#     test_y = np.array(y[-testNb:])\n",
    "#     print(\"    Dataset created!\")\n",
    "        \n",
    "#     #Save\n",
    "# #     saveDataset(train_X, train_y, validation_X, validation_y, test_X, test_y, nbPerGenre, genres, sliceSize)\n",
    "\n",
    "#     return train_X, train_y, validation_X, validation_y, test_X, test_y\n",
    "\n",
    "# #Saves dataset\n",
    "# def saveDataset(train_X, train_y, validation_X, validation_y, test_X, test_y):\n",
    "# #      #Create path for dataset if not existing\n",
    "# #     if not os.path.exists(os.path.dirname(datasetPath)):\n",
    "# #         try:\n",
    "# #             os.makedirs(os.path.dirname(datasetPath))\n",
    "# #         except OSError as exc: # Guard against race condition\n",
    "# #             if exc.errno != errno.EEXIST:\n",
    "# #                 raise\n",
    "\n",
    "#     #SaveDataset\n",
    "#     print(\"[+] Saving dataset... \")\n",
    "#     datasetName = \"main\"\n",
    "#     pickle.dump(train_X, open(\"train_X_{}.p\".format(datasetName), \"wb\" ))\n",
    "#     pickle.dump(train_y, open(\"train_y_{}.p\".format(datasetName), \"wb\" ))\n",
    "#     pickle.dump(validation_X, open(\"validation_X_{}.p\".format(datasetName), \"wb\" ))\n",
    "#     pickle.dump(validation_y, open(\"validation_y_{}.p\".format(datasetName), \"wb\" ))\n",
    "#     pickle.dump(test_X, open(\"test_X_{}.p\".format(datasetName), \"wb\" ))\n",
    "#     pickle.dump(test_y, open(\"test_y_{}.p\".format(datasetName), \"wb\" ))\n",
    "#     print(\"    Dataset saved! ✅💾\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size (1299, 2)\n",
      "data size (1299, 2)\n",
      "X size (1299, 128, 128, 1)\n",
      "y size (1299,)\n",
      "389 129 781\n",
      "    Dataset created!\n",
      "(781, 128, 128, 1) (781,) (389, 128, 128, 1) (389,) (129, 128, 128, 1) (129,)\n",
      "[0 1]\n",
      "(781, 128, 128, 1) (781, 1) (389, 128, 128, 1) (389, 1) (129, 128, 128, 1) (129, 1)\n",
      "[+] Saving dataset... \n",
      "    Dataset saved! ✅💾\n"
     ]
    }
   ],
   "source": [
    "# train_X, train_y, validation_X, validation_y, test_X, test_y = createDataset(128, 0.3, 0.1, True)\n",
    "# print(np.shape(train_X), np.shape(train_y), np.shape(validation_X), np.shape(validation_y), np.shape(test_X), np.shape(test_y))\n",
    "# print(np.unique(train_y))\n",
    "\n",
    "\n",
    "# # print(train_X)\n",
    "# # print(train_y)\n",
    "# # print(validation_X) \n",
    "# # print(validation_y) \n",
    "# # print(test_X) \n",
    "# # print(test_y)\n",
    "# train_y = np.reshape(train_y, (-1, 1))\n",
    "# test_y = np.reshape(test_y, (-1, 1))\n",
    "# validation_y = np.reshape(validation_y, (-1, 1))\n",
    "# print(np.shape(train_X), np.shape(train_y), np.shape(validation_X), np.shape(validation_y), np.shape(test_X), np.shape(test_y))\n",
    "# saveDataset(train_X, train_y, validation_X, validation_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Loading training and validation datasets... \n",
      "    Training and validation datasets loaded! ✅\n",
      "[+] Loading testing dataset... \n",
      "    Testing dataset loaded! ✅\n",
      "(781, 128, 128, 1) (781, 1) (389, 128, 128, 1) (389, 1) (129, 128, 128, 1) (129, 1)\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "def loadDataset():\n",
    "    #Load existing\n",
    "    \n",
    "    datasetName = \"main\"\n",
    "    print(\"[+] Loading training and validation datasets... \")\n",
    "    train_X = pickle.load(open(\"train_X_{}.p\".format(datasetName), \"rb\" ))\n",
    "    train_y = pickle.load(open(\"train_y_{}.p\".format(datasetName), \"rb\" ))\n",
    "    validation_X = pickle.load(open(\"validation_X_{}.p\".format(datasetName), \"rb\" ))\n",
    "    validation_y = pickle.load(open(\"validation_y_{}.p\".format(datasetName), \"rb\" ))\n",
    "    print(\"    Training and validation datasets loaded! ✅\")\n",
    "    print(\"[+] Loading testing dataset... \")\n",
    "    test_X = pickle.load(open(\"test_X_{}.p\".format(datasetName), \"rb\" ))\n",
    "    test_y = pickle.load(open(\"test_y_{}.p\".format(datasetName), \"rb\" ))\n",
    "    print(\"    Testing dataset loaded! ✅\")\n",
    "    return train_X, train_y, validation_X, validation_y, test_X, test_y\n",
    "\n",
    "train_X, train_y, validation_X, validation_y, test_X, test_y = loadDataset()\n",
    "\n",
    "print(np.shape(train_X), np.shape(train_y), np.shape(validation_X), np.shape(validation_y), np.shape(test_X), np.shape(test_y))\n",
    "print(np.unique(train_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "model taken from this article:\n",
    "https://chatbotslife.com/finding-the-genre-of-a-song-with-deep-learning-da8f59a61194\n",
    "'''\n",
    "\n",
    "import tflearn # source ~./bash...\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "def createModel(imageSize):\n",
    "    print(\"[+] Creating model...\")\n",
    "    convnet = input_data(shape=[None, imageSize, imageSize, 1], name='input')\n",
    "\n",
    "#     convnet = conv_2d(convnet, 64, 2, activation='elu', weights_init=\"Xavier\")\n",
    "#     convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "    convnet = conv_2d(convnet, 128, 4, activation='elu', weights_init=\"Xavier\")\n",
    "    convnet = max_pool_2d(convnet, 4)\n",
    "\n",
    "    convnet = conv_2d(convnet, 256, 2, activation='elu', weights_init=\"Xavier\")\n",
    "    convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "    convnet = conv_2d(convnet, 512, 2, activation='elu', weights_init=\"Xavier\")\n",
    "    convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "    \n",
    "    convnet = fully_connected(convnet, 128, activation='relu')\n",
    "    convnet = dropout(convnet, 0.5)\n",
    "\n",
    "    convnet = fully_connected(convnet, 1, activation='softmax') # 2 classes, 1 output\n",
    "    convnet = regression(convnet, optimizer='rmsprop', loss='binary_crossentropy')\n",
    "\n",
    "\n",
    "    model = tflearn.DNN(convnet)\n",
    "    print(\"    Model created! ✅\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Creating model...\n",
      "    Model created! ✅\n"
     ]
    }
   ],
   "source": [
    "nbClasses = 2\n",
    "sliceSize = 128\n",
    "#Model parameters\n",
    "batchSize = 128\n",
    "learningRate = 0.001\n",
    "nbEpoch = 20\n",
    "\n",
    "model = createModel(sliceSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 86  | total loss: \u001b[1m\u001b[32m0.61440\u001b[0m\u001b[0m | time: 24.431s\n",
      "\u001b[2K\r",
      "| RMSProp | epoch: 013 | loss: 0.61440 - binary_acc: 0.7183 -- iter: 256/781\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a99a1199e4f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[+] Training the model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m model.fit(train_X, train_y, n_epoch=nbEpoch, batch_size=batchSize, shuffle=True, \n\u001b[0;32m----> 4\u001b[0;31m           validation_set=(validation_X, validation_y), snapshot_step=100, show_metric=True)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"    Model trained! ✅\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tflearn/models/dnn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_inputs, Y_targets, n_epoch, validation_set, show_metric, batch_size, shuffle, snapshot_epoch, snapshot_step, excl_trainops, validation_batch_size, run_id, callbacks)\u001b[0m\n\u001b[1;32m    214\u001b[0m                          \u001b[0mexcl_trainops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexcl_trainops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                          \u001b[0mrun_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                          callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tflearn/helpers/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, feed_dicts, n_epoch, val_feed_dicts, show_metric, snapshot_step, snapshot_epoch, shuffle_all, dprep_dict, daug_dict, excl_trainops, run_id, callbacks)\u001b[0m\n\u001b[1;32m    337\u001b[0m                                                        \u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0msnapshot_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                                                        \u001b[0msnapshot_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                                                        show_metric)\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                             \u001b[0;31m# Update training state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tflearn/helpers/trainer.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, training_step, snapshot_epoch, snapshot_step, show_metric)\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0mtflearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         _, train_summ_str = self.session.run([self.train, self.summ_op],\n\u001b[0;32m--> 818\u001b[0;31m                                              feed_batch)\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0;31m# Retrieve loss value from summary string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "print(\"[+] Training the model...\")\n",
    "model.fit(train_X, train_y, n_epoch=nbEpoch, batch_size=batchSize, shuffle=True, \n",
    "          validation_set=(validation_X, validation_y), snapshot_step=100, show_metric=True)\n",
    "print(\"    Model trained! ✅\")\n",
    "\n",
    "#Save trained model\n",
    "print(\"[+] Saving the weights...\")\n",
    "model.save('musicDNN.tflearn')\n",
    "print(\"[+] Weights saved! ✅💾\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Loading weights...\n",
      "INFO:tensorflow:Restoring parameters from /Users/sangencre/Desktop/NYU/fall_17/ML/final_project/ML_final_project/src/musicDNN.tflearn\n",
      "    Weights loaded! ✅\n",
      "[+] Test accuracy: 0.813953488372093 \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'denselayer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a7eedb31cc27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[+] Test accuracy: {} \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestAccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenselayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'denselayer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#Load weights\n",
    "print(\"[+] Loading weights...\")\n",
    "model.load('musicDNN.tflearn')\n",
    "print(\"    Weights loaded! ✅\")\n",
    "\n",
    "testAccuracy = model.evaluate(test_X, test_y)[0]\n",
    "print(\"[+] Test accuracy: {} \".format(testAccuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 24\n",
      "(128, 128, 1)\n",
      "INFO:tensorflow:Restoring parameters from /Users/sangencre/Desktop/NYU/fall_17/ML/final_project/ML_final_project/src/musicDNN.tflearn\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on one of the images\n",
    "\n",
    "path = \"./audioclip-1512874035918-5282_spec.png\"\n",
    "imgData = getImageData(path, 128, True)\n",
    "\n",
    "\n",
    "X_predict = imgData\n",
    "# X_predict = np.reshape(X_predict, (1 , 128, 128, 1))\n",
    "print(np.shape(X_predict))\n",
    "# print(X_predict)\n",
    "model.load('musicDNN.tflearn')\n",
    "print(test_y)\n",
    "model.predict(test_X)\n",
    "# testAccuracy = model.evaluate(test_X, test_y)[0]\n",
    "# print(\"[+] Test accuracy: {} \".format(testAccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unfinished attempt to create the same model in TF\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 128, 128, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=128,\n",
    "      kernel_size=[4, 4],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[4, 4], strides=4)\n",
    "\n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=256,\n",
    "      kernel_size=[2, 2],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "        # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv3 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=512,\n",
    "      kernel_size=[2, 2],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Dense Layer\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "    predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "      onehot_labels=onehot_labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
